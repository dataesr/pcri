{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_library import *\n",
    "eic = unzip_zip(ZIPNAME, f\"{PATH_SOURCE}{FRAMEWORK}/\", 'proposals_eicFundPortfolio.json', 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eic=pd.DataFrame(eic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eic.sort_values('proposalNbr')\n",
    "eic.head(5\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://research-and-innovation.ec.europa.eu/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-europe_en\"\n",
    "\"https://research-and-innovation.ec.europa.eu/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-europe/cluster-1-health_en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://research-and-innovation.ec.europa.eu/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-europe/cluster-1-health_en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_path import PATH_SOURCE\n",
    "import time, pandas as pd, os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox .service import Service as FirefoxService\n",
    "from webdriver_manager.firefox  import GeckoDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def get_data_from_html(soup):\n",
    "    response=[]\n",
    "    for res in soup.find_all('eui-card-header-subtitle'):\n",
    "#         print(res.find_all('span')[0].text)\n",
    "#         print(res.find_all('strong')[0].text)\n",
    "#         print(res.find_all('strong')[1].text)\n",
    "        response.append({'topic_code':res.find_all('span')[0].text, \n",
    "                        'type':res.find_all('span')[2].text, \n",
    "                        'open_date':res.find_all('strong')[0].text, \n",
    "                        'deadline':res.find_all('strong')[1].text})\n",
    "    return response\n",
    "\n",
    "def click_next(b):\n",
    "    x = b[2] # 3e element qui convient (après test)\n",
    "    c = x.find_element(By.CLASS_NAME, 'eui-button')\n",
    "    c.click()\n",
    "\n",
    "\n",
    "# def get_topic_info_europa(prog):\n",
    "prog='cluster-1-health'\n",
    "url = f\"https://research-and-innovation.ec.europa.eu/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-europe/{prog}_en\"\n",
    "\n",
    "driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install()))\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "time.sleep(5)  \n",
    "\n",
    "wait = WebDriverWait(driver, 1)\n",
    "wait.until(EC.presence_of_element_located((By.ID,'cookie-consent-banner')))\n",
    "cookie = driver.find_element(By.CLASS_NAME, 'wt-ecl-button')\n",
    "cookie.click()\n",
    "\n",
    "# # click on preview\n",
    "b = driver.find_elements(By.CLASS_NAME, 'wt-ecl-link__label')\n",
    "y=b[0]\n",
    "y.click()\n",
    "\n",
    "\n",
    "\n",
    "html_page = driver.page_source\n",
    "soup = BeautifulSoup(html_page, 'html.parser')\n",
    "soup.find(class_=\"wt-modal--content\").find('div', attrs={\"data-page-number\":\"2\"})\n",
    "\n",
    "\n",
    "\n",
    "    # counter = soup.find('div', class_='eui-paginator__page-range').get_text().strip().replace(',','').replace('–',' ').split(' ')\n",
    "    #     print(counter)\n",
    "    #     new_data = get_data_from_html(soup)\n",
    "    #     print(len(new_data))\n",
    "    #     data += new_data\n",
    "    #     if counter[-3] == counter[-1]:\n",
    "    #         break\n",
    "    #     print('---')\n",
    "    #     b = driver.find_elements(By.CLASS_NAME, 'eui-paginator__page-navigation-item')\n",
    "    #     click_next(b)\n",
    "    #     time.sleep(5)\n",
    "    # #     except:\n",
    "    # #         wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"#cdk-overlay-0 button.btn\"))).click()\n",
    "    # #         driver.execute_script(\"arguments[0].click()\", driver.find_element_by_css_selector(\"#StudentSatisfactionPop button.btn\"))\n",
    "\n",
    "    # pd.to_pickle(data, open(f\"{PATH_SOURCE}{FRAMEWORK}/topic_info_harvest.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config_path import PATH_SOURCE, PATH_WP\n",
    "import time, pandas as pd, requests, fitz, re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox .service import Service as FirefoxService\n",
    "from webdriver_manager.firefox  import GeckoDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "def wp_load(url, year, files_to_load):\n",
    "  \n",
    "    driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    wait = WebDriverWait(driver, 1)\n",
    "    wait.until(EC.presence_of_element_located((By.ID,'cookie-consent-banner')))\n",
    "    cookie = driver.find_element(By.CLASS_NAME, 'wt-ecl-button')\n",
    "    cookie.click()\n",
    "\n",
    "    elements = driver.find_elements(By.XPATH, '//a[@data-wt-preview=\"pdf\" and @href and @data-untranslated-label]')\n",
    "\n",
    "    # Loop through elements and check data-untranslated-label content\n",
    "    for el in elements:\n",
    "\n",
    "        label = el.get_attribute(\"data-untranslated-label\")\n",
    "        href = el.get_attribute(\"href\")\n",
    "        print(f\"{label} -> {href}\")\n",
    "        for key, value in files_to_load.items():\n",
    "            if key in re.sub(r\"\\s+\", \"\", label).lower():\n",
    "                r = requests.get(href, allow_redirects=True)\n",
    "                open(f\"{PATH_WP}{year}/{value}.pdf\", 'wb').write(r.content)\n",
    "                break  # Stop checking once matched\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"Horizon Europe Work programme (2025) - Infrastructures\"\n",
    "\n",
    "for key, value in files_to_load.items():\n",
    "    if key in re.sub(r\"\\s+\", \"\", s).lower():\n",
    "        print(value)\n",
    "#             result_dict[value] = href\n",
    "#             break  # Stop checking once matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_year='2025'\n",
    "url=f'https://research-and-innovation.ec.europa.eu/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-europe/horizon-europe-work-programmes_en#pre-publication-of-work-programme-{wp_year}'\n",
    "# url='https://research-and-innovation.ec.europa.eu/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-europe/horizon-europe-work-programmes_en#pre-publication-of-work-programme-2025'\n",
    "from constant_vars import FRAMEWORK\n",
    "\n",
    "files_to_load = {\"infrastructures\":\"infra\", \n",
    "                \"cluster1\":\"health\",\n",
    "                \"cluster2\":\"cluster2\",\n",
    "                \"cluster3\":\"cluster3\",\n",
    "                \"cluster4\":\"cluster4\",\n",
    "                \"cluster5\":\"cluster5\",\n",
    "                \"cluster6\":\"cluster6\",\n",
    "                \"uropeaninnovationecosystems\":\"eie\",\n",
    "                \"widera\":\"widera\",\n",
    "                \"missions\":\"mission\",\n",
    "                \"neb\":\"neb\"\n",
    "                }\n",
    "\n",
    "# if load_wp==True:\n",
    "wp_load(url, wp_year, files_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_by_wp=[]\n",
    "for k,v in files_to_load.items():\n",
    "    doc = fitz.open(f\"{PATH_WP}{wp_year}/{v}.pdf\")\n",
    "    all_text = chr(12).join([page.get_text() for page in doc])\n",
    "    all_text = all_text.replace('\\n','')\n",
    "    all_text = all_text.strip()\n",
    "    # print(all_text)\n",
    "    match = re.search(r\"table of contents(.*?)budget\", all_text, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        result = match.group(1).strip()\n",
    "        search_text = r'HORIZON-[^:\\s\\\\\\/\\)]*'\n",
    "        l=re.findall(search_text, result)\n",
    "        l=list(set(l))\n",
    "        res={'year':wp_year,\n",
    "        'wp':v,\n",
    "        'calls':list(set(l))}\n",
    "        calls_by_wp.append(res)\n",
    "pd.to_pickle(pd.DataFrame(calls_by_wp), open(f\"{PATH_SOURCE}{FRAMEWORK}/calls_by_wp.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_path import PATH_SOURCE, PATH_WP\n",
    "from constant_vars import FRAMEWORK\n",
    "import time, pandas as pd, requests, fitz, re\n",
    "pdf=[]\n",
    "doc = fitz.open(f\"{PATH_SOURCE}{FRAMEWORK}/MSCA_Keywords.pdf\")\n",
    "for page_num in range(len(doc)):\n",
    "    page = doc[page_num]\n",
    "    text = page.get_text()  # default: plain text extraction\n",
    "    # print(f\"--- Page {page_num + 1} ---\")\n",
    "    # print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "with pdfplumber.open(f\"{PATH_SOURCE}{FRAMEWORK}/MSCA_Keywords.pdf\") as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_tables()\n",
    "        print(text)\n",
    "        # if not text:\n",
    "        #     continue\n",
    "        # lines = text.split('\\n')\n",
    "        # print(lines)\n",
    "#         for line in lines:\n",
    "#             # Filtrer les lignes de bas de page (ex: \"Page 1\", \"1\", etc.)\n",
    "#             if re.match(r\"^\\s*Page\\s*\\d+\\s*$\", line, re.IGNORECASE) or re.match(r\"^\\s*\\d+\\s*$\", line):\n",
    "#                 continue\n",
    "\n",
    "#             # Découper par espace logique ou adapter ici\n",
    "#             parts = line.strip().split()\n",
    "#             all_rows.append(parts)\n",
    "\n",
    "# # Normaliser toutes les lignes pour avoir le même nombre de colonnes\n",
    "# max_cols = max(len(row) for row in all_rows)\n",
    "# normalized = [row + [\"\"] * (max_cols - len(row)) for row in all_rows]\n",
    "\n",
    "# # Créer un DataFrame\n",
    "# df = pd.DataFrame(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=f\"{PATH_SOURCE}{FRAMEWORK}/msca_Keywords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_and_fill_text_to_dataframe():\n",
    "import numpy as np, pandas as pd\n",
    "from config_path import PATH_SOURCE\n",
    "from constant_vars import FRAMEWORK\n",
    "test=f\"{PATH_SOURCE}{FRAMEWORK}/msca_Keywords.txt\"\n",
    "with open(test, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "lines = [line.strip() for line in raw_text.strip().split('\\n') if line.startswith('|')]\n",
    "rows = [line.strip('|').split('|') for line in lines]\n",
    "\n",
    "clean_filtered_rows = [\n",
    "    [cell.strip() for cell in row]\n",
    "    for row in rows\n",
    "    if not any('---' in cell or 'scientific panel' in cell.lower() for cell in row)\n",
    "]\n",
    "\n",
    "# Step 3: Use the original header (before filtering and cleaning)\n",
    "header = [cell.strip() for cell in rows[0]]\n",
    "\n",
    "# Step 4: Create DataFrame\n",
    "df = pd.DataFrame(clean_filtered_rows, columns=header)\n",
    "\n",
    "\n",
    "# # Step 4: Forward-fill missing values\n",
    "df = df.replace('', np.nan).fillna(method='ffill').loc[~df[\"Level 2 keywords\"].isnull()]\n",
    "\n",
    "# Extract the part before the parenthesis\n",
    "df[\"panel_regroupement_name\"] = df[\"Scientific panel\"].str.extract(r\"^(.*?)\\s*\\(\")\n",
    "\n",
    "# Optional: also extract the code as before\n",
    "df[\"panel_regroupement_code\"] = df[\"Scientific panel\"].str.extract(r\"\\((.*?)\\)\")\n",
    "\n",
    "df[[\"panel_code_1\", \"panel_name_1\"]] = df[\"Level 1 keywords\"].str.split('-', n=1, expand=True)\n",
    "\n",
    "df = (df[['panel_regroupement_code', 'panel_regroupement_name', 'panel_code_1', 'panel_name_1', 'Level 2 keywords']]\n",
    "      .rename(columns={\"Level 2 keywords\":\"panel_keywords\"})\n",
    ")\n",
    "# print(df)\n",
    "json_output_path = \"data_files/msca_keywords.json\"\n",
    "df.to_json(json_output_path, orient=\"records\", indent=2, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_shared import work_csv\n",
    "work_csv(df, 'msca_panel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
