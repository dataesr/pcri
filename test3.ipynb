{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b64eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## LOAD bases\n",
      "size _proj: 342190\n",
      "- size part: 1311188\n",
      "involved successful:195,503.0\n",
      "subv_net_laureat:71,730,094,005.4\n",
      "subv_laureat:68,609,787,841.5\n",
      "subv_prop:687,415,105,572.9\n",
      "- def(my_country_code) size df: 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zfriant\\OneDrive\\Github\\pcri\\functions_shared.py:292: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'AU' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[c]==k, 'parent_iso2'] = v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size part: 1308763\n",
      "size part_init with major cols: 1308763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zfriant\\OneDrive\\Github\\pcri\\step5_frameworks\\functions_shared.py:104: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df.loc[df[col].str.contains('ERA(-?)NET', na=False, regex=True), 'euro_partnerships_type'] = 'ERA-NET'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## PROJ cleaning\n",
      "## ENTITIES cleaning\n",
      "#FCT gps_col\n",
      "parent_iso missing : [None]\n",
      "- size entities 226938\n",
      "- ok entities source generalState not null\n",
      "size part without country: 174712\n",
      "size part with country: 175681\n",
      "\n",
      "### LOADING REF_SOURCE\n",
      "- size of ref_source : 507289\n",
      "### 2d - REF_SOURCE -> REF\n",
      "- size remplacement pic: 445\n",
      "- longueur de ref:38268\n",
      "- nb id: 38087\n",
      "- nb id after fill: 38087\n",
      "- si ++id pour un generalPic:           generalPic                     id id_secondaire  \\\n",
      "464437     955557-13        265906719;j5sy1           NaN   \n",
      "263554     859889-18        266900273;etBz7           NaN   \n",
      "464164     955325-18        266900273;etBz7           NaN   \n",
      "303223  888896512000            7Uu6D;bZiTA           NaN   \n",
      "441954     949629419            9wAap;n2X5f           NaN   \n",
      "304279  888898163000      IXHyv;n2X5f;bZiTA           NaN   \n",
      "430638     940565157  R0307bxz06;R04zgvy449           NaN   \n",
      "316671     892207359        Uxr7Z;775665789    199213070W   \n",
      "403226     927638258        n2X5f;552059024    199519291V   \n",
      "382067     917388559            n2X5f;IXJPr    200711920F   \n",
      "382101     917395446            n2X5f;u13se    200612829Y   \n",
      "443179     950071642            n2X5f;zO154    198819289Y   \n",
      "506329     999899378            qPCgk;n2X5f    199812849E   \n",
      "303339  888896738000            tIJ02;FL57b           NaN   \n",
      "303344     888896745            tIJ02;FL57b           NaN   \n",
      "303345  888896745000            tIJ02;FL57b           NaN   \n",
      "306352     889002436            tIJ02;MB44Z           NaN   \n",
      "506402     999907235            u13se;n2X5f           NaN   \n",
      "\n",
      "       country_code_mapping ZONAGE  \n",
      "464437                  FRA    NaN  \n",
      "263554                  FRA    NaN  \n",
      "464164                  FRA    NaN  \n",
      "303223                  FRA    NaN  \n",
      "441954                  FRA    NaN  \n",
      "304279                  FRA    NaN  \n",
      "430638                  CZE    NaN  \n",
      "316671                  FRA    NaN  \n",
      "403226                  FRA    NaN  \n",
      "382067                  FRA    NaN  \n",
      "382101                  FRA    NaN  \n",
      "443179                  FRA    NaN  \n",
      "506329                  FRA    NaN  \n",
      "303339                  FRA    NaN  \n",
      "303344                  FRA    NaN  \n",
      "303345                  FRA    NaN  \n",
      "306352                  FRA    NaN  \n",
      "506402                  FRA    NaN  \n",
      "parent_iso missing : ['ZOI']\n",
      "size de p: 168978\n",
      "cols de p: Index(['generalPic', 'country_code_mapping', 'country_code', 'id',\n",
      "       'id_secondaire', 'ZONAGE', '_merge'],\n",
      "      dtype='object')\n",
      "size p1 pic+cc: 38225\n",
      "size p2 pic cc_parent: 13\n",
      "A faire si possible, vérifier pourquoi des participations avec pic identiques ont un id ou pas nb pic: 261\n",
      "size de new p: 38238, cols: Index(['generalPic', 'country_code_mapping', 'country_code', 'id',\n",
      "       'id_secondaire', 'ZONAGE'],\n",
      "      dtype='object')\n",
      "size part1: 1308763, part: 1308763\n",
      "size participation after add nuts: 1308763, sans nuts name: 196\n",
      "- size entities 38030\n",
      "1- size ent si multi id -> ent_size_to_keep = 38049\n",
      "Index(['generalPic', 'id', 'country_code_mapping', 'id_extend'], dtype='object')\n",
      "### merge ROR\n",
      "- End size entities_tmp+ror_info: 38049\n",
      "size entities_tmp after add ror_info: 38049, entities_size_to_keep: 38049\n",
      "### CATEGORY paysage\n",
      "### merge PAYSAGE\n",
      "- End size entities_tmp+paysage_info: 38049\n",
      "### merge SIRENE\n",
      "- first size sirene : 15870\n",
      "- size sirene : 15870\n",
      "1 - A vérifier -> liste des noms à traiter:\n",
      "                            ens denom_us  \\\n",
      "0                          NaN     None   \n",
      "1                          NaN     None   \n",
      "2                          NaN     None   \n",
      "3                          NaN     None   \n",
      "4                          NaN     None   \n",
      "5                          NaN     None   \n",
      "6                          NaN     None   \n",
      "7   DCNS NAVIRES ARMES LORIENT     None   \n",
      "8       ECOL PRIM JEANNE D ARC     None   \n",
      "9         CLINIQUE BEAU-SOLEIL     None   \n",
      "10                         NaN     None   \n",
      "11                         NaN     None   \n",
      "12                         NaN     None   \n",
      "13                         NaN     None   \n",
      "14                HOPITAL NORD     None   \n",
      "15                         NaN     None   \n",
      "16                         NaN     None   \n",
      "17        GRETA ROUEN MARITIME     None   \n",
      "18                         NaN     None   \n",
      "19                         NaN     None   \n",
      "\n",
      "                                               nom_ul  \n",
      "0                                           MODUL-BIO  \n",
      "1                                            PHYTODIA  \n",
      "2                                            SOLIANCE  \n",
      "3                            BIO RAD LABORATORIES SAS  \n",
      "4                                 LINCOLN ELECTRIC SA  \n",
      "5                                        AXESS EUROPE  \n",
      "6                         CENTRE INTERNAT RECH CANCER  \n",
      "7                                         NAVAL GROUP  \n",
      "8                                   COMMUNE DE MENTON  \n",
      "9                            AESIO SANTE MEDITERRANEE  \n",
      "10                                 PRESTWICK CHEMICAL  \n",
      "11            EUROPEAN SYNCHROTRON RADIATION FACILITY  \n",
      "12                                                BEL  \n",
      "13                                             THALES  \n",
      "14            CENTRE HOSPITALIER REGIONAL DE GRENOBLE  \n",
      "15                              CORDOUAN TECHNOLOGIES  \n",
      "16  AGENCE DE L ENVIRONNEMENT ET DE LA MAITRISE DE...  \n",
      "17              LYCEE ENS GEN TECHNO GUSTAVE FLAUBERT  \n",
      "18                        SOLETANCHE BACHY ENTREPRISE  \n",
      "19                                      CRYPTOEXPERTS  \n",
      "#####\n",
      "- End size entities_tmp+sirene: 38049\n",
      "ATTENTION faire code pour traiter deux siren différents -> ce qui serait bizarre qu'il y ait 2 siren\n",
      "      generalPic         id country_code_mapping  id_extend unused_parent  \\\n",
      "10431  949264020      pgd9B                  FRA      pgd9B           NaN   \n",
      "13888  944056866  752535476                  FRA  752535476           NaN   \n",
      "30629  949204268  775624240                  FRA  775624240           NaN   \n",
      "\n",
      "      ror_category entities_id cj_code  \\\n",
      "10431          NaN       pgd9B    9230   \n",
      "13888          NaN       j7Ls5    5710   \n",
      "30629          NaN       pgd9B    9230   \n",
      "\n",
      "                                         paysage_cj_name sector  ...  \\\n",
      "10431  Association déclarée, reconnue d'utilité publique  privé  ...   \n",
      "13888                SAS, société par actions simplifiée  privé  ...   \n",
      "30629  Association déclarée, reconnue d'utilité publique  privé  ...   \n",
      "\n",
      "      siren_end_date        paysage_siren nb      paysage_category_id  \\\n",
      "10431                 325974269;775624240  1  0YVlb;UfEnK;T9gjR;2SZlU   \n",
      "13888                 501168223;878951094  1                      NaN   \n",
      "30629                 325974269;775624240  1  0YVlb;UfEnK;T9gjR;2SZlU   \n",
      "\n",
      "                                        paysage_category  \\\n",
      "10431  Établissement privé d'enseignement universitai...   \n",
      "13888                                                NaN   \n",
      "30629  Établissement privé d'enseignement universitai...   \n",
      "\n",
      "      paysage_category_priority siret_closeDate        id_m  \\\n",
      "10431               10;30;75;99             NaN         NaN   \n",
      "13888                       NaN      2022-09-01        None   \n",
      "30629               10;30;75;99      2008-01-01  W595026827   \n",
      "\n",
      "                     siren siege  \n",
      "10431  325974269;775624240   NaN  \n",
      "13888  501168223;878951094  True  \n",
      "30629  325974269;775624240  True  \n",
      "\n",
      "[3 rows x 22 columns]\n",
      "taille de entities_tmp avant groupe:38049\n",
      "taille de entities_tmp après groupe 38049\n",
      "### sourcer les identifiants pour getInformations\n",
      "\n",
      "## category woven\n",
      "- categorization missing\n",
      "      source_id entities_name entities_id siren_cj paysage_category\n",
      "6       paysage           NaN       bZiTA      NaN              NaN\n",
      "76      paysage           NaN       vb71K      NaN              NaN\n",
      "137     paysage           NaN       zYXK8      NaN              NaN\n",
      "260     paysage           NaN       Py0K5      NaN              NaN\n",
      "320     paysage           NaN       Lr94O      NaN              NaN\n",
      "...         ...           ...         ...      ...              ...\n",
      "37239     siren           NaN   152000014      NaN              NaN\n",
      "37413   paysage           NaN       O2v0H      NaN              NaN\n",
      "37441   paysage           NaN       5KpJ9      NaN              NaN\n",
      "37452   paysage           NaN       bZiTA      NaN              NaN\n",
      "37461   paysage           NaN       Zz6Vq      NaN              NaN\n",
      "\n",
      "[357 rows x 5 columns]\n",
      "- taille de df après cat: 38049\n",
      "\n",
      "### MIRES\n",
      "size part1 avant: 1308763\n",
      "size part1 -> part_tmp: 1308812\n",
      "Index(['project_id', 'orderNumber', 'generalPic_old', 'pic', 'participates_as',\n",
      "       'role', 'legalName', 'part_total_cost', 'subv', 'subv_net',\n",
      "       'partner_status', 'countryCode', 'legalEntityTypeCode', 'isSme',\n",
      "       'nutsCode', 'stage', 'shortName', 'requestedGrant', 'budget', 'url',\n",
      "       'pic_old', 'country_code_mapping', 'country_code', 'id',\n",
      "       'id_secondaire', 'ZONAGE', 'participation_nuts', 'region_1_name',\n",
      "       'region_2_name', 'regional_unit_name', 'generalPic', 'cat_an',\n",
      "       'category_agregation', 'category_tmp', 'category_woven', 'cj',\n",
      "       'cj_code', 'entities_acronym', 'entities_id', 'entities_name',\n",
      "       'entreprise_flag', 'groupe_acronym', 'groupe_id', 'groupe_name',\n",
      "       'groupe_sector', 'id_extend', 'id_m', 'insee_cat_code',\n",
      "       'insee_cat_name', 'nb', 'operateur_lib', 'operateur_name',\n",
      "       'operateur_num', 'paysage_category', 'paysage_category_id',\n",
      "       'paysage_category_priority', 'paysage_cj_name', 'paysage_siren',\n",
      "       'ror_category', 'sector', 'siege', 'siren', 'siren_cj',\n",
      "       'siren_end_date', 'siret_closeDate', 'source_id', 'unused_parent'],\n",
      "      dtype='object')\n",
      "419905\n",
      "size part2: 131447, nb unique pic_d: 131015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zfriant\\AppData\\Local\\Temp\\ipykernel_13540\\1726910486.py:451: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  part2=part2.groupby(['pic_d']).apply(lambda x: x.sort_values('generalState', key=lambda col: pd.Categorical(col, categories=gen_state, ordered=True)), include_groups=True).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size part2: 119618, nb unique pic_d: 119618\n",
      "11398\n",
      "11398\n",
      "size part_tmp after merge part2: 1308812\n",
      "size part_tmp after merge part2: 1308812\n",
      "size part_tmp after clean string: 1308812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zfriant\\AppData\\Local\\Temp\\ipykernel_13540\\1726910486.py:520: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt['calculated_fund'] = np.where(pt.stage=='successful', pt['subv'], pt['requestedGrant'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size part_tmp after concat with erc: 1308812\n",
      "involved successful:193,082.0\n",
      "subv_net_laureat:71,562,252,054.7\n",
      "subv_laureat:68,609,700,856.6\n",
      "subv_prop:687,414,885,969.0\n",
      "### CORDIS type\n",
      "- size entities_info: 1308812\n",
      "size part_tmp after clean codis legal type: 1308812\n",
      "size part_tmp avant: 1308812\n",
      "size part_tmp after merge countries: 1308812\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, json\n",
    "from step3_entities.references import ref_source_load, ref_source_2d_select\n",
    "from step3_entities.merge_referentiels import merge_paysage, merge_ror, merge_sirene\n",
    "from step3_entities.categories import category_agreg, category_paysage,category_woven, cordis_type, mires\n",
    "from step3_entities.ID_getSourceRef import get_source_ID\n",
    "from step4_calculations.collaborations import collab_base, collab_cross\n",
    "from config_path import PATH_SOURCE, PATH_CLEAN, PATH_REF, PATH_CONNECT\n",
    "from functions_shared import unzip_zip, my_country_code\n",
    "\n",
    "def h20_nom_load():\n",
    "    destination = pd.read_json(open(\"data_files/destination.json\", 'r', encoding='utf-8'))\n",
    "    thema = pd.read_json(open(\"data_files/thema.json\", 'r', encoding='utf-8'))\n",
    "    act = pd.read_json(open(\"data_files/actions_name.json\", 'r', encoding='utf-8'))\n",
    "    topics = unzip_zip('H2020_2022-12-05.json.zip', f\"{PATH_SOURCE}H2020/\", 'topics.json', encode='utf-8')\n",
    "    pilier_fr = pd.read_json(open(\"data_files/H20_pilier.json\", 'r', encoding='utf-8'))\n",
    "    # countries = pd.read_csv(f\"{PATH_SOURCE}H2020/country_current.csv\", sep=';')\n",
    "    countries = pd.read_pickle(f\"{PATH_CLEAN}country_current.pkl\")\n",
    "    actions = pd.read_table(f\"{PATH_CLEAN}actions_current.csv\", sep=\";\")\n",
    "    nuts = pd.read_pickle(f'{PATH_REF}nuts_complet.pkl')\n",
    "    return destination, thema, act, topics, pilier_fr, countries, actions, nuts\n",
    "destination, thema, act, topics, pilier_fr, countries, actions, nuts = h20_nom_load()\n",
    "\n",
    "def h20_load():\n",
    "    print(\"## LOAD bases\")\n",
    "    _proj=pd.read_pickle(f\"{PATH_SOURCE}H2020/H2020_projects.pickle\")\n",
    "    _proj=pd.DataFrame(_proj)\n",
    "    _proj=_proj.replace('#', np.nan)\n",
    "    print(f\"size _proj: {len(_proj)}\")\n",
    "    part=pd.read_pickle(f\"{PATH_SOURCE}H2020/H2020_participation.pickle\")\n",
    "    part=pd.DataFrame(part)\n",
    "    part=part.replace('#', np.nan)\n",
    "    print(f\"- size part: {len(part)}\")\n",
    "    entities = unzip_zip('H2020_2022-12-05.json.zip', f\"{PATH_SOURCE}H2020/\", \"legalEntities.json\", encode='utf-8')\n",
    "    status = pd.read_csv(f\"{PATH_SOURCE}H2020/redressement_status_code.csv\", sep=';', usecols=['project_id','stat_code'], dtype='str')\n",
    "    return _proj, part, entities, status\n",
    "_proj, part, entities, status = h20_load()\n",
    "print(f\"involved successful:{'{:,.1f}'.format(part.loc[(part.stage=='successful'), 'generalPic'].count())}\\nsubv_net_laureat:{'{:,.1f}'.format(part.loc[(part.stage=='successful'), 'subv_net'].sum())}\\nsubv_laureat:{'{:,.1f}'.format(part.loc[(part.stage=='successful'), 'subv'].sum())}\\nsubv_prop:{'{:,.1f}'.format(part.loc[(part.stage=='evaluated'), 'requestedGrant'].sum())}\")\n",
    "\n",
    "country_h20 = my_country_code()\n",
    "\n",
    "part.loc[part.role=='participant', 'role'] = 'partner'\n",
    "# part.loc[part.countryCode=='ZZ', 'country_code_mapping'] = 'ZZZ'\n",
    "part = part[part.participates_as!='utro']\n",
    "part.rename(columns={'order_number':'orderNumber'}, inplace=True)\n",
    "print(f\"size part: {len(part)}\")\n",
    "part_init = part[['project_id', 'orderNumber', 'generalPic_old', 'pic', 'participates_as',\n",
    "    'role', 'legalName', 'part_total_cost', 'subv', 'subv_net',\n",
    "    'partner_status', 'countryCode', 'legalEntityTypeCode', 'isSme',\n",
    "    'nutsCode', 'stage', 'shortName', 'requestedGrant', 'budget', 'url', 'generalPic']]\n",
    "print(f\"size part_init with major cols: {len(part_init)}\")\n",
    "\n",
    "\n",
    "part_init=(part_init.merge(country_h20[['iso2', 'iso3', 'parent_iso3']], how='left', left_on='countryCode', right_on='iso2')\n",
    ".rename(columns={'iso3':'country_code_mapping', 'parent_iso3':'country_code'})\n",
    ".drop(columns='iso2'))\n",
    "\n",
    "if any(part_init[part_init.country_code_mapping.isnull()].countryCode.unique()):\n",
    "    print(part_init[part_init.country_code_mapping.isnull()].countryCode.unique())\n",
    "\n",
    "##status\n",
    "_proj = _proj.merge(status, how='inner', on='project_id')\n",
    "_proj.loc[_proj.stage=='evaluated', 'status_code'] = _proj.stat_code\n",
    "_proj.drop(columns=['stat_code'], inplace=True)\n",
    "\n",
    "l=['RIA','IA','CSA']\n",
    "tmp=_proj.loc[(~_proj.action_id.isin(['MSCA','ERC'])&(~_proj.action_2_id.isnull())&(_proj.action_id!='SME')),\n",
    "['action_2_id']].drop_duplicates()\n",
    "tmp['action_code'] = tmp['action_2_id'].str.extract(\"(\" + \"|\".join(l) +\")\", expand=False)\n",
    "_proj = _proj.merge(tmp, how='left', on='action_2_id')\n",
    "_proj.loc[_proj.action_code.isnull(), 'action_code'] = _proj.action_id\n",
    "\n",
    "\n",
    "def h20_topics(df, act, actions, destination, pilier_fr, thema):\n",
    "\n",
    "    proj = (_proj.rename(columns={'pilier':'pilier_name_en', 'topicCode':'topic_code','topicDescription':'topic_name',\n",
    "                                    'action_2_id':'action_code2', 'action_2_name':'action_name2', \n",
    "                                    'action_3_id':'action_code3', 'action_3_name':'action_name3'})\n",
    "        .drop(columns=['action_name'])\n",
    "        .merge(pilier_fr, how='left', on='pilier_name_en')\n",
    "        .merge(act, how='left', on='action_code'))\n",
    "\n",
    "    #euratom\n",
    "    proj.loc[proj.pilier_name_fr=='Euratom', 'pilier_name_en'] = 'Euratom'\n",
    "    proj.loc[(proj.pilier_name_fr=='Euratom')&(proj.topic_code.str.contains('NFRP')), 'programme_code'] = 'NFRP'\n",
    "    proj.loc[(proj.pilier_name_fr=='Euratom')&(proj.programme_code=='NFRP'), 'programme_name_en'] = 'Nuclear fission and radiation protection'\n",
    "    proj.loc[proj.call_id=='EURATOM-Adhoc-2014-20', 'programme_code'] = 'Fusion'\n",
    "    proj.loc[proj.call_id=='EURATOM-Adhoc-2014-20', 'programme_name_en'] = 'Fusion Energy'\n",
    "    proj.loc[(proj.pilier_name_fr=='Euratom')&(proj.call_id!='EURATOM-Adhoc-2014-20')&(proj.programme_code!='NFRP'), 'programme_code'] = 'Euratom-other'\n",
    "    proj.loc[(proj.pilier_name_fr=='Euratom')&(proj.call_id!='EURATOM-Adhoc-2014-20')&(proj.programme_code!='NFRP'), 'programme_name_en'] = 'Euratom other actions'\n",
    "\n",
    "    euratom = pd.read_csv('data_files/euratom_thema_all_FP.csv', sep=';', na_values='')\n",
    "    proj = proj.merge(euratom[['topic_area', 'thema_code', 'thema_name_en']], how='left', left_on='topic_code', right_on='topic_area', suffixes=['', '_t'])\n",
    "    proj.loc[(~proj.thema_code_t.isnull()), 'thema_code'] = proj.loc[(~proj.thema_code_t.isnull()), 'thema_code_t']\n",
    "    proj.loc[(~proj.thema_name_en_t.isnull()), 'thema_name_en'] = proj.loc[(~proj.thema_name_en_t.isnull()), 'thema_name_en_t']\n",
    "    # proj = proj.filter(regex=r'.*(?<!_t)$').drop(columns='topic_area')\n",
    "\n",
    "    # JU-JTI\n",
    "    proj.loc[proj.action_code=='Art185', 'destination_code'] = proj.loc[proj.action_code=='Art185'].thema_code\n",
    "\n",
    "    proj.loc[proj.thema_code.str.contains('JU', na=False), 'destination_code'] = proj.thema_code.str.replace('JU','').str.strip()\n",
    "    proj.loc[(proj.destination_code=='Eurostars2'), 'destination_next_fp'] = \"INNOVSMES\"\n",
    "\n",
    "    proj.loc[(proj.call_id.str.contains('PPP',na=False))|(proj.call_id.str.contains('JTI',na=False))|(proj.topic_code.str.contains('JTI',na=False)), 'destination_code'] = proj['action_code2'].str.split('-').str[0]\n",
    "    proj.loc[proj.call_id.str.contains('JTI',na=False)&(proj.action_code2.isnull()), 'destination_code'] = proj['call_id'].str.split('-').str[2]\n",
    "    proj.loc[(proj.thema_code=='CS2'), 'destination_code'] = 'CS2'\n",
    "    proj.loc[(proj.destination_code.str.contains('BBI', na=False)), 'destination_next_fp'] = 'CBE'\n",
    "    proj.loc[(proj.thema_code=='BBI'), 'thema_code'] = np.nan\n",
    "    proj.loc[(proj.destination_code=='EuroHPC'), 'destination_next_fp'] = 'EUROHPC'\n",
    "    proj.loc[(proj.thema_code=='ECSEL'), 'destination_code'] = 'ECSEL'\n",
    "    proj.loc[(proj.destination_code=='ECSEL'), 'destination_next_fp'] = 'CHIPS'\n",
    "    proj.loc[(proj.destination_code=='CS2'), 'destination_next_fp'] = 'CLEAN-AVIATION'\n",
    "    proj.loc[(proj.destination_code=='FCH2'), 'destination_next_fp'] = 'CLEANH2'\n",
    "    proj.loc[(proj.destination_code=='IMI2'), 'destination_next_fp'] = 'IHI'\n",
    "    proj.loc[(proj.destination_code=='Shift2Rail'), 'destination_next_fp'] = \"EU-RAIL\"\n",
    "    proj.loc[(~proj.destination_code.isnull())&(proj.destination_next_fp.isnull()), 'destination_next_fp'] = proj.loc[(~proj.destination_code.isnull())&(proj.destination_next_fp.isnull())].destination_code\n",
    "    l=['KDT', 'CBE','EUROHPC', 'CLEAN-AVIATION', 'CLEANH2', 'IHI', 'CHIPS', \"EU-RAIL\"]\n",
    "    proj.loc[(~proj.destination_next_fp.isnull()), 'thema_code'] = 'JU-JTI'\n",
    "\n",
    "    # MSCA / ERC\n",
    "    proj.loc[proj.programme_code=='MSCA', 'programme_next_fp'] = 'MSCA'\n",
    "    proj.loc[proj.programme_code=='ERC', 'programme_next_fp'] = 'ERC'\n",
    "\n",
    "    # ### ajustement MSCA\n",
    "    msca_correspondence = pd.read_table('data_files/msca_correspondence.csv', sep=\";\")\n",
    "\n",
    "    msca_correspondence = msca_correspondence[msca_correspondence.framework=='H2020'].drop(columns='framework')\n",
    "    proj.loc[(proj.thema_code=='MSCA')&(proj.action_code3.isnull()), 'action_code3'] = proj.action_code2\n",
    "\n",
    "    proj.loc[(proj.thema_code=='MSCA'), 'destination_code'] = proj.loc[(proj.thema_code=='MSCA')].action_code3.str.replace('MSCA-', '').str.strip()\n",
    "    proj.loc[(proj.thema_code=='MSCA'), 'destination_name_en'] = proj.loc[(proj.thema_code=='MSCA')].action_name2.str.replace('Marie Skłodowska-Curie', '').str.strip() +'-'+ proj.loc[(proj.thema_code=='MSCA')].action_name3.dropna()\n",
    "\n",
    "    # m = proj.loc[(proj.action_code=='MSCA'), ['action_code3']].drop_duplicates()\n",
    "    proj = proj.merge(msca_correspondence, how='left', left_on='action_code3', right_on='old')\n",
    "    proj.loc[~proj.new.isnull(), 'destination_next_fp'] = proj.loc[~proj.new.isnull()].new\n",
    "    proj.loc[(proj.thema_code=='MSCA')&(proj.destination_next_fp.isnull()),'destination_next_fp'] = 'MSCA-OTHER'\n",
    "    # m = m.merge(actions[['destination_detail_code','destination_detail_name_en']].drop_duplicates(), how='left', on='destination_detail_code')\n",
    "    proj.loc[proj.destination_code=='NIGHT', 'destination_name_en'] = \"European researchers' Night\"\n",
    "    proj.loc[proj.destination_code=='RISE', 'destination_name_en'] = \"Research and innovation staff exchange\"\n",
    "\n",
    "    # proj.loc[proj.programme_code=='MSCA', 'programme_name_en'] = 'Marie Skłodowska-Curie Actions (MSCA)'\n",
    "\n",
    "\n",
    "    ### ajustement ERC\n",
    "    proj.loc[proj.thema_code=='ERC', 'destination_code'] = proj.loc[proj.thema_code=='ERC'].action_code2.str.split('-').str[1]\n",
    "    proj.loc[proj.destination_code=='POC-LS', 'destination_code'] = \"POC\"\n",
    "    proj.loc[(proj.thema_code=='ERC')&(proj.destination_code.isnull()), 'destination_code'] = 'ERC-OTHER'\n",
    "    proj.loc[(proj.action_code=='ERC'), 'action_code2'] = np.nan\n",
    "    proj.loc[(proj.action_code=='ERC'), 'action_name2'] = np.nan\n",
    "\n",
    "    # FET\n",
    "    proj.loc[proj.programme_code=='FET', 'thema_code'] = 'PATHFINDER'\n",
    "    proj.loc[(proj.programme_code=='FET')&(proj.action_code=='SGA'), 'destination_code'] = proj.loc[(proj.programme_code=='FET')&(proj.action_code=='SGA')].topic_code.str.split('-').str[2].str.upper()\n",
    "    proj.loc[(proj.programme_code=='FET')&(proj.destination_code.isnull()), 'destination_code'] = proj.loc[(proj.programme_code=='FET')&(proj.destination_code.isnull())].topic_code.str.split('-').str[0].str.upper()\n",
    "    proj.loc[(proj.programme_code=='FET')&(proj.topic_code.str.contains('BAT-')), 'destination_code'] = 'BATTERY'\n",
    "\n",
    "    proj.loc[proj.programme_code=='FET', 'thema_name_en'] = np.nan\n",
    "\n",
    "    proj.loc[(proj.call_id.str.contains(\"FETOPEN-2018-2019-2020\"))|(proj.topic_code.str.contains(\"FETPROACT-EIC\")), 'destination_next_fp'] = 'ACCELERATOR'\n",
    "\n",
    "    # SMEInst\n",
    "    proj.loc[(proj.topic_code.str.contains('EIC-SMEInst')), 'destination_next_fp'] = 'ACCELERATOR'\n",
    "\n",
    "    proj.loc[proj.destination_next_fp=='ACCELERATOR', 'programme_next_fp'] = 'EIC'\n",
    "\n",
    "    proj.loc[(proj.programme_code=='SME')&(proj.thema_code!='JU-JTI'), 'thema_name_en'] = np.nan\n",
    "\n",
    "    # INFRA\n",
    "    proj.loc[proj.programme_code=='INFRA', 'thema_code'] = proj.programme_code\n",
    "    proj.loc[proj.programme_code=='INFRA', 'destination_code'] = proj.loc[proj.programme_code=='INFRA'].topic_code.str.split('-').str[0]\n",
    "    proj.loc[(proj.programme_code=='INFRA')&(proj.destination_code=='LC'), 'destination_code'] = 'GREEN-DEAL'\n",
    "    proj.loc[proj.destination_code.isin(['LC','IBA','SGA']), 'destination_code'] = np.nan\n",
    "\n",
    "    # EIT\n",
    "    proj.loc[proj.action_code=='KICS', 'pilier_name_en'] = 'Innovative Europe'\n",
    "    proj.loc[proj.action_code=='KICS', 'programme_code'] = 'EIT'\n",
    "    proj.loc[proj.action_code=='KICS', 'programme_name_en'] = 'The European Institute of Innovation and Technology (EIT)'\n",
    "\n",
    "    # # WIDENING COST\n",
    "    proj.loc[proj.programme_code.str.contains('TWINING|WIDESPREAD|NCPNET', na=False), 'thema_code'] = 'ACCESS'\n",
    "    proj.loc[proj.programme_code.str.contains('ERA', na=False), 'thema_code'] = 'TALENTS'\n",
    "    proj.loc[proj.programme_code.str.contains('INTNET', na=False), 'thema_code'] = 'COST'\n",
    "    proj.loc[(proj.pilier_name_en=='Spreading excellence and widening participation')&(proj.programme_code!='ERA'), 'programme_code'] = 'Widening'\n",
    "    proj.loc[proj.programme_code=='Widening', 'programme_name_en'] = 'Widening participation and spreading excellence'\n",
    "\n",
    "    proj.loc[(proj.programme_code=='Widening')&(proj.thema_code.isnull()), 'thema_code'] = 'WIDENING-OTHER'\n",
    "\n",
    "    proj.loc[(proj.programme_code.isin(['BIOTECH','ADVMANU','ADVMAT', 'NMP']))&(proj.thema_code.isnull()), 'thema_code'] = proj.loc[(proj.programme_code.isin(['BIOTECH','ADVMANU','ADVMAT', 'NMP']))&(proj.thema_code.isnull())].programme_code\n",
    "    proj.loc[(proj.programme_code.isin(['BIOTECH','ADVMANU','ADVMAT', 'NMP']))&(proj.thema_name_en.isnull()), 'thema_name_en'] = proj.loc[(proj.programme_code.isin(['BIOTECH','ADVMANU','ADVMAT', 'NMP']))&(proj.thema_name_en.isnull())].programme_name_en\n",
    "    proj.loc[(proj.programme_code.isin(['BIOTECH','ADVMANU','ADVMAT', 'NMP'])), 'programme_code'] = 'NMBP'\n",
    "    proj.loc[proj.programme_code=='NMBP', 'programme_name_en'] = 'Nanotechnologies, Advanced Materials, Advanced Manufacturing and Processing, and Biotechnology'\n",
    "\n",
    "    dest = destination[['destination_code', 'destination_name_en']]\n",
    "    proj = proj.merge(dest, how='left', on='destination_code', suffixes=('', '_x'))\n",
    "    proj.loc[proj.destination_name_en.isnull(), 'destination_name_en'] = proj.loc[proj.destination_name_en.isnull()].destination_name_en_x\n",
    "\n",
    "    proj = proj.merge(thema.loc[~thema.dest_h20.isnull(), ['thema_code', 'dest_h20']], how='left', left_on='thema_code', right_on='dest_h20', suffixes=['','_x'])\n",
    "    proj.loc[~proj.thema_code_x.isnull(), 'thema_code'] = proj.thema_code_x\n",
    "    proj.drop(columns=['thema_code_x','dest_h20'], inplace=True)\n",
    "    proj = proj.merge(thema, how='left', on='thema_code', suffixes=['','_x'])\n",
    "    proj.loc[~proj.thema_name_en_x.isnull(), 'thema_name_en'] = proj.thema_name_en_x\n",
    "\n",
    "    proj.drop(columns=['thema_name_en_x','dest_h20', 'destination_name_en_x', 'thema_code_t', 'thema_name_en_t', 'new', 'old'], inplace=True)\n",
    "    return proj\n",
    "\n",
    "def euro_partnerships(proj):\n",
    "    from step5_frameworks.functions_shared import ju_jti_parterships, eranet_partnerships\n",
    "    # proj.loc[proj.action_code=='Art185', 'euro_partnerships_type'] = 'Art-185'\n",
    "    # proj.loc[(proj.thema_code=='JU-JTI')&(proj.euro_partnerships_type.isnull()), 'euro_partnerships_type'] = 'Art-187'\n",
    "    # proj.loc[proj.thema_code=='JU-JTI', 'euro_partnerships_type_next_fp'] = 'JU-JTI'\n",
    "    proj=ju_jti_parterships(proj, 'H20')\n",
    "    proj.loc[proj.programme_code=='EIT', 'euro_partnerships_type'] = 'EIT KICs'\n",
    "    proj.loc[proj.programme_code=='EIT', 'euro_partnerships_type_next_fp'] = 'EIT KICs'\n",
    "\n",
    "    # proj.loc[proj.action_code=='ERA-NET-Cofund', 'euro_partnerships_type'] = 'ERA-NET-COFUND'\n",
    "    # proj.loc[proj.action_code=='ERA-NET-Cofund', 'euro_partnerships_type_next_fp'] = 'co-funded'\n",
    "    proj=eranet_partnerships(proj, 'H20')\n",
    "    proj.loc[proj.acronym=='CoBioTech', 'euro_ps_name'] = 'ERA CoBioTech'\n",
    "    \n",
    "    proj.loc[(proj.topic_code.isin(['NFRP-2018-6', 'SC1-PM-05-2016', 'EURATOM', 'NFRP-07-2015']))&(proj.action_code=='COFUND'), 'euro_partnerships_type'] = 'EJP-COFUND'\n",
    "    proj.loc[(proj.action_code=='COFUND')&(proj.acronym.str.contains('EJP')), 'euro_partnerships_type'] = 'EJP-COFUND'\n",
    "    proj.loc[(proj.action_code=='COFUND')&(proj.acronym.str.contains('EJP')), 'euro_partnerships_type_next_fp'] = 'co-funded'\n",
    "\n",
    "    proj.loc[proj.topic_name.str.contains('PPP'), 'euro_partnerships_type'] = 'cPPP'\n",
    "    proj.loc[(proj.topic_code.str.contains('GV-', regex=True, na=False))&(proj.programme_code=='TPT')&(proj.euro_partnerships_type.isnull()), 'euro_partnerships_type'] = 'cPPP'\n",
    "    proj.loc[(proj.topic_name.str.contains('photonics', case=False, na=False))&(proj.programme_code=='ICT')&(proj.euro_partnerships_type.isnull()), 'euro_partnerships_type'] = 'cPPP'\n",
    "    robotics=[\"ict-27-2017\", \"ict-28-2017\", \"ict-25-2016\", \"ict-26-2016\", \"ict-24-2015\", \"ict-23-2014\"]\n",
    "    for i in robotics:        \n",
    "        proj.loc[(proj.programme_code=='ICT')&(proj.topic_code.str.contains(r\"^\"+i, case=False, regex=True)), 'euro_partnerships_type'] = 'cPPP'\n",
    "\n",
    "    proj.loc[proj.euro_partnerships_type.str.contains('cPPP', na=False), 'euro_partnerships_type_next_fp'] = 'co-programmed'\n",
    "\n",
    "    proj.loc[proj.euro_partnerships_type=='EIT KICs', 'euro_ps_name'] = proj.loc[proj.euro_partnerships_type=='EIT KICs'].thema_name_en\n",
    "    # proj.loc[proj.euro_partnerships_type=='ERA-NET-COFUND', 'euro_ps_name'] = proj.loc[proj.euro_partnerships_type=='ERA-NET-COFUND'].acronym\n",
    "    \n",
    "    # proj.loc[proj.euro_partnerships_type_next_fp=='JU-JTI', 'euro_ps_name'] = proj.loc[proj.euro_partnerships_type_next_fp=='JU-JTI'].destination_code\n",
    "    proj.loc[(proj.euro_partnerships_type_next_fp=='co-funded')&(proj.euro_ps_name.isnull())&(proj.destination_code.isnull()), 'euro_ps_name'] = proj.loc[(proj.euro_partnerships_type_next_fp=='co-funded')&(proj.euro_ps_name.isnull())&(proj.destination_code.isnull())].acronym\n",
    "    proj.loc[(proj.euro_partnerships_type_next_fp=='co-funded')&(proj.euro_ps_name.isnull())&(~proj.destination_code.isnull()), 'euro_ps_name'] = proj.loc[(proj.euro_partnerships_type_next_fp=='co-funded')&(proj.euro_ps_name.isnull())&(~proj.destination_code.isnull())].destination_code\n",
    "    proj.loc[(proj.euro_partnerships_type=='cPPP')&(proj.call_id.str.contains('EEB|SPIRE|FOF|EE', regex=True, case=False, na=False)), 'euro_ps_name'] = proj.loc[(proj.euro_partnerships_type=='cPPP')&(proj.call_id.str.contains('EEB|SPIRE|FOF|EE', regex=True, case=False, na=False))].call_id.str.split('-').str[1]\n",
    "    proj.loc[(proj.euro_partnerships_type=='cPPP')&(proj.euro_ps_name.isnull()), 'euro_ps_name'] = proj.loc[(proj.euro_partnerships_type=='cPPP')&(proj.euro_ps_name.isnull())].topic_name.str.extract(r\"^(.+ PPP)\", expand=False)\n",
    "    proj.loc[(proj.euro_partnerships_type=='cPPP')&(proj.euro_ps_name=='EE'), 'euro_ps_name'] = proj.loc[(proj.euro_partnerships_type=='cPPP')&(proj.euro_ps_name=='EE')].topic_name.str.extract(r\"^(?:\\()(EeB|SPIRE|FoF)\", expand=False)\n",
    "    proj.loc[(proj.euro_partnerships_type=='cPPP')&(proj.topic_code.str.contains('GV', na=False)), 'euro_ps_name'] = 'EGVI'\n",
    "    proj.loc[(proj.euro_partnerships_type=='cPPP')&(proj.euro_ps_name=='Big data PPP'), 'euro_ps_name'] = 'BDVA'\n",
    "    proj.loc[(proj.euro_partnerships_type=='cPPP')&(proj.topic_name.str.contains('photonics', case=False, na=False))&(proj.programme_code=='ICT'), 'euro_ps_name'] = 'Photonics'\n",
    "    proj.loc[(proj.euro_partnerships_type=='cPPP')&(proj.programme_code=='ICT')&(proj.euro_ps_name.isnull()), 'euro_ps_name'] = 'Robotics SPARC'\n",
    "    return proj.assign(euro_partnerships_flag=np.where(proj.euro_partnerships_type.isnull(), False, True)) \n",
    "\n",
    "\n",
    "def cPPP_destination_name(proj):\n",
    "    mask=(proj.euro_partnerships_type=='cPPP')\n",
    "    proj.loc[mask&(proj.euro_ps_name=='EGVI'), 'destination_name'] = 'European Green Vehicles Initiative'\n",
    "    proj.loc[mask&(proj.euro_ps_name=='SPIRE'), 'destination_name'] = 'Sustainable Process Industry'\n",
    "    proj.loc[mask&(proj.euro_ps_name=='FoF'), 'destination_name'] = 'Factories of the future'\n",
    "    proj.loc[mask&(proj.euro_ps_name=='EeB'), 'destination_name'] = 'Energy-Efficient Buildings'\n",
    "    proj.loc[mask&(proj.euro_ps_name=='5G PPP'), 'destination_name'] = 'Advanced 5G Network for the future'\n",
    "    proj.loc[mask&(proj.euro_ps_name=='BDVA'), 'destination_name'] = 'Big Data Value Association '\n",
    "    proj.loc[mask&(proj.euro_ps_name=='Cybersecurity PPP'), 'destination_name'] = 'Connected digital single market'\n",
    "    proj.loc[mask&(proj.euro_ps_name=='Photonics'), 'destination_name'] = 'Photonics21 Association'\n",
    "    proj.loc[mask&(proj.euro_ps_name=='Robotics SPARC'), 'destination_name'] = 'Robotics SPARC'\n",
    "    return proj\n",
    "\n",
    "def proj_cleaning(proj):\n",
    "    print(\"## PROJ cleaning\")\n",
    "    from functions_shared import website_to_clean\n",
    "    for i in ['title','abstract', 'free_keywords', 'eic_panels', 'url_project']:\n",
    "        proj[i]=proj[i].str.replace('\\\\n|\\\\t|\\\\r|\\\\s+', ' ', regex=True).str.strip()\n",
    "        \n",
    "    kw = proj[['project_id','stage','free_keywords']].drop_duplicates()\n",
    "    kw = kw.assign(free_keywords = kw.free_keywords.str.split(';|,')).explode('free_keywords')\n",
    "    kw['free_keywords'] = kw.free_keywords.str.replace('\\\\.+', '', regex=True)\n",
    "    kw = kw.loc[kw.free_keywords.str.len()>3].drop_duplicates()\n",
    "    kw.free_keywords = kw.free_keywords.groupby(level=0).apply(lambda x: '|'.join(x.str.strip().unique()))\n",
    "    kw = kw.drop_duplicates()\n",
    "\n",
    "    proj = proj.drop(columns='free_keywords').merge(kw, how='left', on=['project_id','stage']).drop_duplicates()    \n",
    "        \n",
    "    proj.loc[proj.url_project.str.contains('project/rcn', na=False), 'url_project']=np.nan\n",
    "\n",
    "    proj.mask(proj=='', inplace=True)  \n",
    "    for i,row in proj.iterrows():\n",
    "        if row.loc['url_project'] is not None:\n",
    "            proj.at[i, 'project_webpage'] = website_to_clean(row['url_project'])\n",
    "\n",
    "    proj.mask(proj=='', inplace=True)  \n",
    "\n",
    "    for d in ['call_deadline', 'signature_date',  'start_date', 'end_date', 'submission_date', 'ecorda_date']:\n",
    "        proj[d] = proj[d].astype('datetime64[ns]')\n",
    "\n",
    "    proj['proposal_expected_number'] = proj['proposal_expected_number'].astype('float')\n",
    "    return proj\n",
    "\n",
    "\n",
    "def entities_cleaning(df, country_h20, p):\n",
    "    print(\"## ENTITIES cleaning\")\n",
    "    from functions_shared import gps_col, num_to_string\n",
    "    df = pd.DataFrame(df)\n",
    "    df = gps_col(df)\n",
    "    df = df.loc[~df.generalPic.isnull()]\n",
    "    \n",
    "    df = (df.merge(country_h20[['iso2', 'iso3', 'parent_iso3']], how='left', left_on='countryCode', right_on='iso2')\n",
    "        .drop(columns='iso2')\n",
    "        .rename(columns={'parent_iso3':'country_code', 'iso3': 'country_code_mapping'}))\n",
    "    print(f\"parent_iso missing : {df[df.country_code.isnull()].countryCode.unique()}\")\n",
    "    df.loc[df.country_code.isnull(), 'country_code'] = df.loc[df.country_code.isnull()].country_code_mapping \n",
    "\n",
    "    c = ['pic', 'generalPic']\n",
    "    df[c] = df[c].map(num_to_string)\n",
    "    print(f\"- size entities {len(df)}\")\n",
    "\n",
    "    if len(df[df.generalState.isnull()])>0:\n",
    "        print(\"- entities source generalState -> new state (processing into entities_single)\")\n",
    "    else:\n",
    "        print(\"- ok entities source generalState not null\")\n",
    "\n",
    "    lien_genCalcPic = p[['generalPic_old', 'pic']].drop_duplicates()\n",
    "    print(f\"size part without country: {len(p[['generalPic_old', 'pic']].drop_duplicates())}\\nsize part with country: {len(p[['generalPic_old', 'pic', 'countryCode']].drop_duplicates())}\")\n",
    "    df = lien_genCalcPic.merge(df, how='inner', left_on=['generalPic_old','pic'], right_on=['generalPic','pic']).drop_duplicates()\n",
    "    return df\n",
    "\n",
    "proj = h20_topics(_proj, act, actions, destination, pilier_fr, thema)\n",
    "proj = euro_partnerships(proj)\n",
    "proj=cPPP_destination_name(proj)\n",
    "proj = proj_cleaning(proj)\n",
    "entities = entities_cleaning(entities, country_h20, part_init)\n",
    "\n",
    "def ref_select(FP):\n",
    "    ref_source = ref_source_load('ref')\n",
    "    # traitement ref select le FP, id non null ou/et ZONAGE non null\n",
    "    ref, genPic_to_new = ref_source_2d_select(ref_source, FP)\n",
    "    ror = pd.read_pickle(f\"{PATH_REF}ror_df.pkl\")\n",
    "    paysage = pd.read_pickle(f\"{PATH_REF}paysage_df.pkl\")\n",
    "    sirene = pd.read_pickle(f\"{PATH_REF}sirene_df.pkl\")\n",
    "    ### si besoin de charger groupe\n",
    "    groupe = pd.read_pickle(f\"{PATH_REF}H20_groupe.pkl\")\n",
    "    return ref, genPic_to_new, ror, paysage, sirene, groupe\n",
    "ref, genPic_to_new, ror, paysage, sirene, groupe = ref_select('H20')\n",
    "\n",
    "print(f\"- si ++id pour un generalPic: {ref[ref.id.str.contains(';', na=False)]}\")\n",
    "ref = (ref.merge(country_h20[['iso3', 'parent_iso3']], how='left', left_on='country_code_mapping', right_on='iso3')\n",
    "    .drop(columns='iso3')\n",
    "    .rename(columns={'parent_iso3':'country_code'}))\n",
    "print(f\"parent_iso missing : {ref[ref.country_code.isnull()].country_code_mapping.unique()}\")\n",
    "ref.loc[ref.country_code.isnull(), 'country_code'] = ref.loc[ref.country_code.isnull()].country_code_mapping \n",
    "\n",
    "\n",
    "########################################################################\n",
    "p=part_init[['generalPic', 'country_code_mapping', 'country_code']].drop_duplicates()\n",
    "print(f\"size de p: {len(p)}\")\n",
    "p = p.merge(ref, how='left', on=['generalPic', 'country_code_mapping', 'country_code'], indicator=True).drop_duplicates()\n",
    "print(f\"cols de p: {p.columns}\") #168 978\n",
    "\n",
    "# p1 pic+ccm commun\n",
    "p1 = p.loc[p['_merge']=='both'].drop(columns=['_merge'])\n",
    "print(f\"size p1 pic+cc: {len(p1)}\")# 62 928\n",
    "\n",
    "\n",
    "p2 = (p.loc[p['_merge']=='left_only'].drop(columns=['_merge', 'id', 'ZONAGE', 'id_secondaire'])\n",
    "    .merge(ref.drop(columns=['country_code_mapping']), \n",
    "            how='inner', left_on=['generalPic', 'country_code'], right_on=['generalPic', 'country_code']).drop_duplicates()\n",
    "    )\n",
    "print(f\"size p2 pic cc_parent: {len(p2)}\")\n",
    "\n",
    "\n",
    "# acteurs sans identifiant dont le pic à plusieurs pays ou le pic certaines participations ont un identifiant et pas d'autres \n",
    "p3 = (p.loc[p['_merge']=='left_only'].drop(columns=['_merge', 'country_code_mapping', 'id', 'ZONAGE'])\n",
    "    .merge(ref, how='inner', on=['generalPic']).drop_duplicates())\n",
    "if not p3.empty:\n",
    "    print(f\"A faire si possible, vérifier pourquoi des participations avec pic identiques ont un id ou pas nb pic: {len(p3.generalPic.unique())}\")\n",
    "\n",
    "p = pd.concat([p1,p2], ignore_index=True).drop_duplicates()\n",
    "print(f\"size de new p: {len(p)}, cols: {p.columns}\")\n",
    "\n",
    "part1 = part_init.merge(p, how='left', on=['generalPic', 'country_code_mapping', 'country_code'])\n",
    "print(f\"size part1: {len(part1)}, part: {len(part_init)}\")\n",
    "\n",
    "# gestion code nuts\n",
    "part1.loc[(part1.nutsCode.str.len()>2), 'nuts_code'] = part1.nutsCode\n",
    "part1 = (part1.merge(nuts, how='left', on='nuts_code')\n",
    "            .drop_duplicates()\n",
    "            .rename(columns={'nuts_code':'participation_nuts'}))\n",
    "print(f\"size participation after add nuts: {len(part1)}, sans nuts name: {len(part1.loc[(~part1.participation_nuts.isnull())&(part1.region_1_name.isnull())])}\")\n",
    "\n",
    "\n",
    "### entities\n",
    "entities_tmp = part1.loc[~part1.id.isnull(), ['generalPic','id','country_code_mapping']].drop_duplicates()\n",
    "print(f\"- size entities {len(entities_tmp)}\")\n",
    "if any(entities_tmp.id.str.contains(';')):\n",
    "    entities_tmp = entities_tmp.assign(id_extend=entities_tmp.id.str.split(';')).explode('id_extend')\n",
    "    ent_size_to_keep = len(entities_tmp)\n",
    "    print(f\"1- size ent si multi id -> ent_size_to_keep = {ent_size_to_keep}\\n{entities_tmp.columns}\")\n",
    "\n",
    "entities_tmp = merge_ror(entities_tmp, ror)\n",
    "print(f\"size entities_tmp after add ror_info: {len(entities_tmp)}, entities_size_to_keep: {ent_size_to_keep}\")\n",
    "\n",
    "# PAYSAGE\n",
    "### si besoin de charger paysage pickle\n",
    "paysage_category = pd.read_pickle(f\"{PATH_SOURCE}paysage_category.pkl\")\n",
    "cat_filter = category_paysage(paysage_category)\n",
    "entities_tmp = merge_paysage(entities_tmp, paysage, cat_filter)\n",
    "\n",
    "# SIRENE\n",
    "### si besoin de charger paysage pickle\n",
    "entities_tmp = merge_sirene(entities_tmp, sirene)\n",
    "entities_tmp['nb']=entities_tmp.groupby(['generalPic', 'id_extend', 'country_code_mapping'])['entities_id'].transform('count')\n",
    "if any(entities_tmp['nb']>1):\n",
    "    print(f\"doublons: {entities_tmp.loc[entities_tmp['nb']>1, ['generalPic', 'id_extend', 'country_code_mapping', 'entities_id', 'nb']]}\")\n",
    "    entities_tmp=entities_tmp.loc[~entities_tmp.entities_id.isin(['889664413', '808994164'])]\n",
    "\n",
    "entities_tmp.loc[(~entities_tmp.id.isnull())&(entities_tmp.entities_id.isnull()), 'entities_id'] = entities_tmp.id\n",
    "entities_tmp['siren']=entities_tmp.loc[entities_tmp.entities_id.str.contains('^[0-9]{9}$|^[0-9]{14}$', na=False)].entities_id.str[:9]\n",
    "entities_tmp.loc[entities_tmp.siren.isnull(), 'siren']=entities_tmp.paysage_siren\n",
    "\n",
    "#groupe entreprises\n",
    "# recuperation tous les siren pour lien avec groupe -> creation var SIREN \n",
    "entities_tmp.loc[~entities_tmp.siren.isnull(), \"siren\"] = entities_tmp.loc[~entities_tmp.siren.isnull(), \"siren\"].str.split().apply(set).str.join(\";\")\n",
    "\n",
    "if any(entities_tmp.siren.str.contains(';', na=False)):\n",
    "    print(f\"ATTENTION faire code pour traiter deux siren différents -> ce qui serait bizarre qu'il y ait 2 siren\\n{entities_tmp[entities_tmp.siren.str.contains(';', na=False)]}\")\n",
    "# else:\n",
    "print(f\"taille de entities_tmp avant groupe:{len(entities_tmp)}\")\n",
    "entities_tmp=entities_tmp.merge(groupe, how='left', on='siren')\n",
    "\n",
    "print(f\"taille de entities_tmp après groupe {len(entities_tmp)}\")\n",
    "entities_tmp = entities_tmp.merge(get_source_ID(entities_tmp, 'entities_id'), how='left', on='entities_id')\n",
    "\n",
    "# traitement catégorie\n",
    "entities_tmp = category_woven(entities_tmp, sirene)\n",
    "entities_tmp = category_agreg(entities_tmp)\n",
    "entities_tmp = mires(entities_tmp)\n",
    "\n",
    "print(f\"size part1 avant: {len(part1)}\")\n",
    "part_tmp = part1.merge(genPic_to_new, how='left', on=['generalPic', 'country_code_mapping'])\n",
    "part_tmp = part_tmp.rename(columns={'generalPic':'pic_old', 'pic_new':'generalPic'})\n",
    "part_tmp.loc[part_tmp.generalPic.isnull(), 'generalPic'] = part_tmp.loc[part_tmp.generalPic.isnull(), 'pic_old']\n",
    "part_tmp = part_tmp.merge(entities_tmp.drop(columns='id'), how='left', on=['generalPic', 'country_code_mapping'])\n",
    "print(f\"size part1 -> part_tmp: {len(part_tmp)}\\n{part_tmp.columns}\")\n",
    "\n",
    "print(len(part_tmp[(part_tmp.entities_name.isnull())]))\n",
    "part2=part_tmp.loc[(part_tmp.entities_name.isnull()), ['generalPic','entities_id', 'country_code_mapping', 'source_id']]\n",
    "part2.loc[part2.entities_id.str.contains('-', na=False), 'pic_d'] = part2.loc[part2.entities_id.str.contains('-', na=False)].entities_id.str.split('-').str[0]\n",
    "part2.loc[part2.pic_d.isnull(), 'pic_d'] = part2.loc[part2.pic_d.isnull()].generalPic\n",
    "\n",
    "part2 = part2.drop_duplicates()\n",
    "print(f\"size part2: {len(part2)}, nb unique pic_d: {part2.pic_d.nunique()}\")\n",
    "part2 = (part2.merge(entities, how='inner', left_on='pic_d', right_on='generalPic')[\n",
    "            ['pic_d','entities_id','legalName', 'businessName', 'legalEntityTypeCode', 'generalState']]\n",
    "        .rename(columns={'businessName':'shortName'})\n",
    "        .drop_duplicates()\n",
    "        )\n",
    "\n",
    "gen_state=['VALIDATED', 'DECLARED', 'DEPRECATED', 'SLEEPING', 'SUSPENDED', 'BLOCKED']\n",
    "part2=part2.groupby(['pic_d']).apply(lambda x: x.sort_values('generalState', key=lambda col: pd.Categorical(col, categories=gen_state, ordered=True)), include_groups=True).reset_index(drop=True)\n",
    "part2=part2.groupby(['pic_d']).head(1).drop(columns='generalState')\n",
    "print(f\"size part2: {len(part2)}, nb unique pic_d: {part2.pic_d.nunique()}\")\n",
    "\n",
    "part3=(part_tmp.loc[(~part_tmp.generalPic.isin(part2.pic_d.unique()))&(part_tmp.entities_name.isnull())]\n",
    "    .sort_values(['generalPic','legalName', 'shortName'], ascending=False))\n",
    "print(part3.generalPic.nunique())\n",
    "\n",
    "part3=(part3.groupby(['generalPic', 'country_code_mapping'])\n",
    "    .first().reset_index()[['generalPic', 'country_code_mapping', 'legalName', 'shortName', 'legalEntityTypeCode']]\n",
    "    .reset_index(drop=True)\n",
    "    .drop_duplicates()\n",
    "    )\n",
    "print(part3.generalPic.nunique())\n",
    "\n",
    "part_tmp = part_tmp.merge(part2, how='left', left_on='generalPic', right_on='pic_d', suffixes=['', '_x'])\n",
    "part_tmp.loc[~part_tmp.legalName_x.isnull(), 'legalName'] = part_tmp.legalName_x\n",
    "part_tmp.loc[~part_tmp.shortName_x.isnull(), 'shortName'] = part_tmp.shortName_x\n",
    "part_tmp.loc[~part_tmp.legalEntityTypeCode_x.isnull(), 'legalEntityTypeCode'] = part_tmp.legalEntityTypeCode_x\n",
    "print(f\"size part_tmp after merge part2: {len(part_tmp)}\")\n",
    "\n",
    "part_tmp = part_tmp.merge(part3, how='left', on=['generalPic', 'country_code_mapping'], suffixes=['', '_y'])\n",
    "part_tmp.loc[~part_tmp.legalName_y.isnull(), 'legalName'] = part_tmp.legalName_y\n",
    "part_tmp.loc[~part_tmp.shortName_y.isnull(), 'shortName'] = part_tmp.shortName_y\n",
    "part_tmp.loc[~part_tmp.legalEntityTypeCode_y.isnull(), 'legalEntityTypeCode'] = part_tmp.legalEntityTypeCode_y\n",
    "part_tmp.drop(part_tmp.columns[part_tmp.columns.str.endswith(('_x','_y'))], axis=1, inplace=True)\n",
    "print(f\"size part_tmp after merge part2: {len(part_tmp)}\")\n",
    "\n",
    "liste=['legalName', 'shortName']\n",
    "for i in liste:\n",
    "    part_tmp[i] = part_tmp[i].apply(lambda x: x.capitalize().strip() if isinstance(x, str) else x)\n",
    "\n",
    "part_tmp.loc[part_tmp.entities_name.isnull(), 'entities_name'] = part_tmp.legalName\n",
    "part_tmp.loc[part_tmp.entities_acronym.isnull(), 'entities_acronym'] = part_tmp.shortName\n",
    "part_tmp.loc[part_tmp.entities_id.isnull(), 'entities_id'] = \"pic\"+part_tmp.generalPic.map(str)\n",
    "\n",
    "part_tmp.rename(columns={'legalName':'entities_name_source',\n",
    "                        'shortName':'entities_acronym_source'}, inplace=True)\n",
    "\n",
    "for i in ['entities_acronym', 'entities_name','entities_acronym_source', 'entities_name_source']:\n",
    "    part_tmp[i] = part_tmp[i].str.replace('\\\\n|\\\\t|\\\\r|\\\\s+', ' ', regex=True).str.strip()\n",
    "print(f\"size part_tmp after clean string: {len(part_tmp)}\")\n",
    "\n",
    "##########################################################\n",
    "\n",
    "# create calculated_fund and coordination_number\n",
    "part_tmp = (part_tmp\n",
    "            .assign(calculated_fund=np.where(part_tmp.stage=='successful', part_tmp['subv_net'], part_tmp['requestedGrant']), \n",
    "                    coordination_number=np.where(part_tmp.role=='coordinator', 1, 0)))\n",
    "\n",
    "\n",
    "#############################################################\n",
    "### ERC\n",
    "\n",
    "proj_erc=proj.loc[proj.action_id=='ERC', ['project_id', 'destination_code']].drop_duplicates()\n",
    "part_tmp=part_tmp.merge(proj_erc, how='left', on='project_id', indicator=True)\n",
    "part_tmp.loc[part_tmp._merge=='both', 'fund_ent_erc'] = part_tmp.loc[part_tmp._merge=='both'].calculated_fund\n",
    "\n",
    "# traitement erc ROLE\n",
    "part_tmp['erc_role'] = 'other'\n",
    "part_tmp.loc[(part_tmp.stage=='evaluated')&(part_tmp.destination_code=='SyG')&((part_tmp.participates_as=='host')|(part_tmp.role=='coordinator')), 'erc_role'] = 'PI'\n",
    "part_tmp.loc[(part_tmp.stage=='successful')&(part_tmp.destination_code=='SyG')&(part_tmp.participates_as=='beneficiary')&(pd.to_numeric(part_tmp.orderNumber, errors='coerce')<5.), 'erc_role'] = 'PI'\n",
    "part_tmp.loc[(part_tmp.role=='coordinator')&(part_tmp.destination_code!='SyG'), 'erc_role'] = 'PI'\n",
    "part_tmp.loc[(part_tmp.destination_code=='SyG')&(part_tmp.role=='coordinator'), 'role'] = 'CO-PI'\n",
    "part_tmp.loc[(part_tmp.erc_role=='PI')&(part_tmp.role!='CO-PI'), 'role'] = 'PI'\n",
    "\n",
    "# traitement subv pour ERC\n",
    "    #calcul budget ERC\n",
    "pt = part_tmp.loc[(part_tmp._merge=='both')&(part_tmp.destination_code!='SyG')]\n",
    "pt['calculated_fund'] = np.where(pt.stage=='successful', pt['subv'], pt['requestedGrant'])\n",
    "spt = pt.loc[pt.stage=='evaluated', ['project_id', 'requestedGrant']].groupby(['project_id'])['requestedGrant'].sum().reset_index()\n",
    "pt = pt.merge(spt, how='left', on='project_id', suffixes=('', '_y'))\n",
    "pt.loc[pt.stage=='evaluated', 'calculated_fund'] = pt.loc[pt.stage=='evaluated'].requestedGrant_y\n",
    "pt.loc[pt.erc_role!='PI', 'calculated_fund'] = 0\n",
    "\n",
    "from functions_shared import work_csv\n",
    "work_csv(pt, 'pt_20')\n",
    "############################################\n",
    "\n",
    "part_tmp = pd.concat([part_tmp[~part_tmp.project_id.isin(pt.project_id.unique())], pt], ignore_index=True)\n",
    "print(f\"size part_tmp after concat with erc: {len(part_tmp)}\")\n",
    "\n",
    "part_tmp.drop(columns=['destination_code','requestedGrant_y', '_merge'], inplace=True)\n",
    "\n",
    "part_tmp = part_tmp.assign(number_involved=1)\n",
    "part_tmp['nb'] = part_tmp.id.str.split(';').str.len()\n",
    "for i in ['subv', 'subv_net', 'requestedGrant', 'calculated_fund', 'fund_ent_erc']:\n",
    "    part_tmp[i] = np.where(part_tmp['nb']>1, part_tmp[i]/part_tmp['nb'], part_tmp[i])\n",
    "print(f\"involved successful:{'{:,.1f}'.format(part_tmp.loc[(part_tmp.stage=='successful'), 'number_involved'].sum())}\\nsubv_net_laureat:{'{:,.1f}'.format(part_tmp.loc[(part_tmp.stage=='successful'), 'subv_net'].sum())}\\nsubv_laureat:{'{:,.1f}'.format(part_tmp.loc[(part_tmp.stage=='successful'), 'subv'].sum())}\\nsubv_prop:{'{:,.1f}'.format(part_tmp.loc[(part_tmp.stage=='evaluated'), 'requestedGrant'].sum())}\")\n",
    "\n",
    "\n",
    "proj_no_coord = proj[(proj.thema_code.isin(['ACCELERATOR','COST']))|(proj.destination_code.isin(['SNLS','PF']))|(proj.action_code3.str.contains('SNLS', na=False))|(proj.thema_code=='ERC')].project_id.to_list()\n",
    "\n",
    "part_tmp.loc[part_tmp.project_id.isin(proj_no_coord), 'coordination_number'] = 0\n",
    "part_tmp = part_tmp.assign(with_coord=True)\n",
    "part_tmp.loc[part_tmp.project_id.isin(proj_no_coord), 'with_coord'] = False\n",
    "\n",
    "part_tmp.rename(columns={'ZONAGE':'extra_joint_organization'}, inplace=True)\n",
    "part_tmp = part_tmp.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "part_tmp = part_tmp.assign(is_ejo=np.where(part_tmp.extra_joint_organization.isnull(), 'Sans', 'Avec'))\n",
    "\n",
    "# merge cordis type\n",
    "part_tmp.loc[part_tmp.legalEntityTypeCode.isnull(), 'legalEntityTypeCode'] = np.nan\n",
    "part_tmp = cordis_type(part_tmp)\n",
    "print(f\"size part_tmp after clean codis legal type: {len(part_tmp)}\")\n",
    "\n",
    "# merge countries \n",
    "if any(part_tmp.country_code_mapping.isnull()):\n",
    "    print(f\"ATTENTION ! country_code_mapping null: {part_tmp[part_tmp.country_code_mapping.isnull()].countryCode.unique()}\")\n",
    "else:\n",
    "    part_tmp = (part_tmp\n",
    "                .merge(countries[['countryCode_iso3', 'country_name_en']]\n",
    "                        .rename(columns={'countryCode_iso3':'country_code_mapping', 'country_name_en': 'country_name_mapping'}), \n",
    "                        how='left', on='country_code_mapping')\n",
    "                .drop_duplicates())\n",
    "    print(f\"size part_tmp avant: {len(part_tmp)}\")\n",
    "\n",
    "if any(part_tmp.country_code.isnull()):\n",
    "    print(f\"ATTENTION ! country_code null: {part_tmp[part_tmp.country_code.isnull()].country_code_mapping.unique()}\")\n",
    "else:\n",
    "    cc=(countries[['countryCode_iso3', 'country_name_en',\n",
    "    'country_association_code_2020', 'country_association_name_2020_en', 'country_group_association_code_2020',\n",
    "    'country_group_association_name_2020_en', 'country_group_association_name_2020_fr', 'country_name_fr', 'article1',\n",
    "    'article2']]\n",
    "    .drop_duplicates()\n",
    "    .rename(columns={'countryCode_iso3': 'country_code',\n",
    "                        'country_association_code_2020':'country_association_code',\n",
    "                        'country_association_name_2020_en':'country_association_name_en', \n",
    "                        'country_group_association_code_2020':'country_group_association_code',\n",
    "                        'country_group_association_name_2020_en':'country_group_association_name_en',\n",
    "                        'country_group_association_name_2020_fr':'country_group_association_name_fr'}))\n",
    "    \n",
    "    undef=pd.DataFrame(json.load(open('data_files/countries_undef.json', 'r+', encoding='UTF-8'))).drop(columns=[])\n",
    "    cc=pd.concat([cc, undef], ignore_index=True)\n",
    "\n",
    "    part_tmp = part_tmp.merge(cc, how='left', on='country_code')\n",
    "    \n",
    "print(f\"size part_tmp after merge countries: {len(part_tmp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14915245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>country_code_mapping_x</th>\n",
       "      <th>country_name_mapping_y</th>\n",
       "      <th>country_name_mapping_x</th>\n",
       "      <th>country_name_en</th>\n",
       "      <th>country_association_code</th>\n",
       "      <th>country_association_name_en</th>\n",
       "      <th>country_group_association_code</th>\n",
       "      <th>country_group_association_name_en</th>\n",
       "      <th>country_group_association_name_fr</th>\n",
       "      <th>country_name_fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173898</th>\n",
       "      <td>ZZZ</td>\n",
       "      <td>ZZ</td>\n",
       "      <td>ZZZ</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not available</td>\n",
       "      <td>UNDEF</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Indéfini</td>\n",
       "      <td>Non connu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country_code countryCode country_code_mapping_x country_name_mapping_y  \\\n",
       "173898          ZZZ          ZZ                    ZZZ          Not available   \n",
       "\n",
       "       country_name_mapping_x country_name_en country_association_code  \\\n",
       "173898                    NaN   Not available                    UNDEF   \n",
       "\n",
       "       country_association_name_en country_group_association_code  \\\n",
       "173898                     Unknown                        Unknown   \n",
       "\n",
       "       country_group_association_name_en country_group_association_name_fr  \\\n",
       "173898                           Unknown                          Indéfini   \n",
       "\n",
       "       country_name_fr  \n",
       "173898       Non connu  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_tmp.loc[part_tmp.country_code=='ZZZ', ['country_code', 'countryCode', 'country_code_mapping_x'  , 'country_name_mapping_y',  'country_name_mapping_x', 'country_name_en', 'country_association_code',\n",
    "       'country_association_name_en', 'country_group_association_code',\n",
    "       'country_group_association_name_en',\n",
    "       'country_group_association_name_fr', 'country_name_fr']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3011ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name_en</th>\n",
       "      <th>country_association_code</th>\n",
       "      <th>country_association_name_en</th>\n",
       "      <th>country_group_association_code</th>\n",
       "      <th>country_group_association_name_en</th>\n",
       "      <th>country_group_association_name_fr</th>\n",
       "      <th>country_name_fr</th>\n",
       "      <th>article1</th>\n",
       "      <th>article2</th>\n",
       "      <th>country_code_mapping</th>\n",
       "      <th>country_name_mapping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>THIRD-OCEF</td>\n",
       "      <td>Other Countries which get Exceptional Funding</td>\n",
       "      <td>THIRD</td>\n",
       "      <td>Other countries</td>\n",
       "      <td>Pays tiers</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>des</td>\n",
       "      <td>les</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>THIRD</td>\n",
       "      <td>Other Third Countries</td>\n",
       "      <td>THIRD</td>\n",
       "      <td>Other countries</td>\n",
       "      <td>Pays tiers</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>d'</td>\n",
       "      <td>l'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>THIRD-OCAF</td>\n",
       "      <td>Other Countries which get Automatic Funding</td>\n",
       "      <td>THIRD</td>\n",
       "      <td>Other countries</td>\n",
       "      <td>Pays tiers</td>\n",
       "      <td>Angola</td>\n",
       "      <td>d'</td>\n",
       "      <td>l'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIA</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>THIRD-OCEF</td>\n",
       "      <td>Other Countries which get Exceptional Funding</td>\n",
       "      <td>THIRD</td>\n",
       "      <td>Other countries</td>\n",
       "      <td>Pays tiers</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>du</td>\n",
       "      <td>le</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>ASSOCIATED</td>\n",
       "      <td>Associated Countries</td>\n",
       "      <td>MEMBER-ASSOCIATED</td>\n",
       "      <td>Member States or associated</td>\n",
       "      <td>Pays membres ou associés</td>\n",
       "      <td>Albanie</td>\n",
       "      <td>d'</td>\n",
       "      <td>l'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>ANT</td>\n",
       "      <td>Netherlands Antilles (Disestablished 2011)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antilles néerlandaises (dissolution 2011)</td>\n",
       "      <td>des</td>\n",
       "      <td>les</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>CPT</td>\n",
       "      <td>Clipperton Island</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clipperton</td>\n",
       "      <td>de la</td>\n",
       "      <td>la</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>ZOE</td>\n",
       "      <td>European organisations area</td>\n",
       "      <td>ZOE</td>\n",
       "      <td>European organisations area</td>\n",
       "      <td>ZOE</td>\n",
       "      <td>European organisations area</td>\n",
       "      <td>Zone organisations européennes</td>\n",
       "      <td>Zone organisations européennes</td>\n",
       "      <td>de</td>\n",
       "      <td>la</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>ZOI</td>\n",
       "      <td>International organisations area</td>\n",
       "      <td>ZOI</td>\n",
       "      <td>International organisations area</td>\n",
       "      <td>ZOI</td>\n",
       "      <td>International organisations area</td>\n",
       "      <td>Zone organisations internationales</td>\n",
       "      <td>Zone organisations internationales</td>\n",
       "      <td>de</td>\n",
       "      <td>la</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>ZZZ</td>\n",
       "      <td>Not available</td>\n",
       "      <td>UNDEF</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Indéfini</td>\n",
       "      <td>Non connu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZ</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    country_code                             country_name_en  \\\n",
       "0            ABW                                       Aruba   \n",
       "1            AFG                                 Afghanistan   \n",
       "2            AGO                                      Angola   \n",
       "3            AIA                                    Anguilla   \n",
       "4            ALB                                     Albania   \n",
       "..           ...                                         ...   \n",
       "240          ANT  Netherlands Antilles (Disestablished 2011)   \n",
       "241          CPT                           Clipperton Island   \n",
       "242          ZOE                 European organisations area   \n",
       "243          ZOI            International organisations area   \n",
       "244          ZZZ                               Not available   \n",
       "\n",
       "    country_association_code                    country_association_name_en  \\\n",
       "0                 THIRD-OCEF  Other Countries which get Exceptional Funding   \n",
       "1                      THIRD                          Other Third Countries   \n",
       "2                 THIRD-OCAF    Other Countries which get Automatic Funding   \n",
       "3                 THIRD-OCEF  Other Countries which get Exceptional Funding   \n",
       "4                 ASSOCIATED                           Associated Countries   \n",
       "..                       ...                                            ...   \n",
       "240                      NaN                                            NaN   \n",
       "241                      NaN                                            NaN   \n",
       "242                      ZOE                    European organisations area   \n",
       "243                      ZOI               International organisations area   \n",
       "244                    UNDEF                                        Unknown   \n",
       "\n",
       "    country_group_association_code country_group_association_name_en  \\\n",
       "0                            THIRD                   Other countries   \n",
       "1                            THIRD                   Other countries   \n",
       "2                            THIRD                   Other countries   \n",
       "3                            THIRD                   Other countries   \n",
       "4                MEMBER-ASSOCIATED       Member States or associated   \n",
       "..                             ...                               ...   \n",
       "240                            NaN                               NaN   \n",
       "241                            NaN                               NaN   \n",
       "242                            ZOE       European organisations area   \n",
       "243                            ZOI  International organisations area   \n",
       "244                        Unknown                           Unknown   \n",
       "\n",
       "      country_group_association_name_fr  \\\n",
       "0                            Pays tiers   \n",
       "1                            Pays tiers   \n",
       "2                            Pays tiers   \n",
       "3                            Pays tiers   \n",
       "4              Pays membres ou associés   \n",
       "..                                  ...   \n",
       "240                                 NaN   \n",
       "241                                 NaN   \n",
       "242      Zone organisations européennes   \n",
       "243  Zone organisations internationales   \n",
       "244                            Indéfini   \n",
       "\n",
       "                               country_name_fr article1 article2  \\\n",
       "0                                        Aruba      des      les   \n",
       "1                                  Afghanistan       d'       l'   \n",
       "2                                       Angola       d'       l'   \n",
       "3                                     Anguilla       du       le   \n",
       "4                                      Albanie       d'       l'   \n",
       "..                                         ...      ...      ...   \n",
       "240  Antilles néerlandaises (dissolution 2011)      des      les   \n",
       "241                                 Clipperton    de la       la   \n",
       "242             Zone organisations européennes       de       la   \n",
       "243         Zone organisations internationales       de       la   \n",
       "244                                  Non connu      NaN      NaN   \n",
       "\n",
       "    country_code_mapping country_name_mapping  \n",
       "0                    NaN                  NaN  \n",
       "1                    NaN                  NaN  \n",
       "2                    NaN                  NaN  \n",
       "3                    NaN                  NaN  \n",
       "4                    NaN                  NaN  \n",
       "..                   ...                  ...  \n",
       "240                  NaN                  NaN  \n",
       "241                  NaN                  NaN  \n",
       "242                  NaN                  NaN  \n",
       "243                  NaN                  NaN  \n",
       "244                  ZZZ        Not available  \n",
       "\n",
       "[245 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instr = pd.read_csv('data_files/instru_nomenclature.csv', sep=';')\n",
    "act=pd.read_json(open(\"data_files/actions_name.json\", 'r', encoding='utf-8'))\n",
    "\n",
    "erc_correspondence = pd.read_json(open(\"data_files/ERC_correspondance.json\", 'r', encoding='utf-8'))\n",
    "thema = pd.read_json(open(\"data_files/thema.json\", 'r', encoding='utf-8'))\n",
    "destination = pd.read_json(open(\"data_files/destination.json\", 'r', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def themes_cleaning(proj):\n",
    "    print(f\"## FP7 themes\\n- size proj before themes-action cleaning:{len(proj)}\")\n",
    "\n",
    "\n",
    "    # # ERC\n",
    "    erc_correspondence = pd.read_json(open(\"data_files/ERC_correspondance.json\", 'r', encoding='utf-8'))\n",
    "\n",
    "    proj.loc[proj.prog_abbr=='ERC', 'thema_code'] = 'ERC'\n",
    "    proj.loc[(proj.prog_abbr=='ERC')&(proj.instrument.str.contains('POC', na=False)), 'instrument'] = 'ERC-POC'\n",
    "    proj = (proj.merge(erc_correspondence, how='left', left_on=['instrument'], right_on=['old'])\n",
    "            .rename(columns={'new':'destination_code'})\n",
    "            .drop(columns='old'))\n",
    "    proj.loc[(proj.thema_code=='ERC')&(proj.destination_code.isnull()), 'destination_code'] = 'ERC-OTHER'\n",
    "\n",
    "    proj.loc[proj.thema_code=='ERC', 'programme_next_fp'] = 'ERC'\n",
    "\n",
    "\n",
    "    # # MSCA\n",
    "    df = proj.loc[(proj.prog_abbr=='PEOPLE')|(proj.instrument.str.startswith('MC-')), ['prog_abbr', 'call_id', 'instrument']].drop_duplicates()\n",
    "    df['inst'] = df['instrument'].str.replace('MC-', '')\n",
    "\n",
    "    df=thema_msca_cleaning(df, 'FP7')\n",
    "    proj = proj.merge(df, how='left', on=['prog_abbr', 'call_id', 'instrument'], suffixes=('', '_t'))\n",
    "\n",
    "    selected_columns = [col[:-2] for col in proj.columns if col.endswith('_t')]\n",
    "    for i in selected_columns:\n",
    "        proj.loc[~proj[f\"{i}_t\"].isnull(), i] = proj.loc[~proj[f\"{i}_t\"].isnull()][f\"{i}_t\"]\n",
    "    proj = proj.filter(regex=r'.*(?<!_t)$')\n",
    "    proj.loc[proj.thema_code=='MSCA', 'programme_next_fp'] = 'MSCA'\n",
    "    print(f\"- size proj after msca: {proj.loc[proj.stage=='successful'].project_id.nunique()}, nb project_id: {len(proj.loc[proj.stage=='successful'])}\")\n",
    "\n",
    "    # #euratom\n",
    "    df = proj.loc[proj.pilier.isin(['EURATOM']), ['prog_abbr', 'area_abbr']].assign(topic_area=proj.area_abbr)\n",
    "    df = thema_euratom_cleaning(df, 'FP7')\n",
    "    proj = proj.merge(df, how='left', on=['prog_abbr', 'area_abbr'], suffixes=('', '_t'))\n",
    "\n",
    "    selected_columns = [col[:-2] for col in proj.columns if col.endswith('_t')]\n",
    "    for i in selected_columns:\n",
    "        proj.loc[~proj[f\"{i}_t\"].isnull(), i] = proj.loc[~proj[f\"{i}_t\"].isnull()][f\"{i}_t\"]\n",
    "    proj = proj.filter(regex=r'.*(?<!_t)$')\n",
    "\n",
    "    #ju_jti\n",
    "    proj.loc[proj.prog_abbr.str.contains('JTI', na=False), 'thema_code'] = 'JU-JTI'\n",
    "    proj.loc[proj.prog_abbr.str.contains('JTI', na=False),  'destination_code'] = proj.loc[proj.prog_abbr.str.contains('JTI', na=False)].instrument.str.split('-').str[-1]\n",
    "    proj.loc[proj.area_abbr=='JTI-CS', 'destination_code'] = 'CLEAN-SKY'\n",
    "\n",
    "    proj.loc[(proj.destination_code=='CLEAN-SKY'), 'destination_next_fp'] = 'CLEAN-AVIATION'\n",
    "    proj.loc[(proj.destination_code=='FCH'), 'destination_next_fp'] = 'CLEANH2'\n",
    "    proj.loc[(proj.destination_code=='IMI'), 'destination_next_fp'] = 'IHI'\n",
    "    proj.loc[(proj.destination_code.isin(['ENIAC','ARTEMIS'])), 'destination_next_fp'] = 'Chips'\n",
    "    # proj.loc[proj.thema_code=='JU-JTI', 'action_code'] = proj.fp_specific_instrument.str.split('-').str[1]\n",
    "\n",
    "    # WIDENING COST\n",
    "    proj.loc[proj.area_abbr.str.contains('COST', na=False), 'thema_code'] = 'COST'\n",
    "    proj.loc[proj.area_abbr.str.contains('COST', na=False), 'programme_next_fp'] = 'Widening'\n",
    "\n",
    "    destination = pd.read_json(open(\"data_files/destination.json\", 'r', encoding='utf-8'))\n",
    "    proj.loc[(~proj.thema_code.isin(['MSCA','ERC']))&(proj.destination_code.isnull()), 'destination_code'] = proj.area_abbr\n",
    "    # proj.loc[proj.destination_code.isnull(), 'destination_code'] = proj.thema_code+'-OTHER'\n",
    "    proj = proj.merge(destination[['destination_code', 'destination_name_en']], how='left', on='destination_code')\n",
    "    proj.loc[(~proj.destination_code.isnull())&(proj.destination_name_en.isnull()), 'destination_name_en'] = proj.area_lib\n",
    "\n",
    "    thema = pd.read_json(open(\"data_files/thema.json\", 'r', encoding='utf-8'))\n",
    "    proj = proj.merge(thema[['thema_code', 'thema_name_en']], how='left', on='thema_code')\n",
    "    proj.loc[(~proj.thema_code.isnull())&(proj.thema_name_en.isnull()), 'destination_name_en'] = proj.prog_lib\n",
    "\n",
    "\n",
    "    proj.loc[proj.programme_code.isnull(), 'programme_code'] = proj.prog_abbr\n",
    "    proj.loc[proj.programme_name_en.isnull(), 'programme_name_en'] = proj.prog_lib\n",
    "\n",
    "    proj['pilier_name_en'] = proj.pilier.str.capitalize()\n",
    "\n",
    "    # action\n",
    "    instr = pd.read_csv('data_files/instru_nomenclature.csv', sep=';')\n",
    "    proj = proj.merge(instr, how='left', on='instrument').drop(columns=['instrument_name']).rename(columns={'name':'action_name'})\n",
    "    proj.loc[proj.destination_code=='NIGHT', 'action_next_fp'] = 'MSCA'   \n",
    "\n",
    "\n",
    "    if any(proj.action_code.isnull()):\n",
    "        print(proj[proj.action_code.isnull()].instrument.unique())   \n",
    "        \n",
    "    print(f\"- size proj: {len(proj.drop_duplicates())}\")\n",
    "\n",
    "    return proj.drop_duplicates()\n",
    "test=themes_cleaning(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns\n",
    "# test.loc[~test.programme_code.isnull(),['pilier_name_en', 'pilier', 'prog_abbr', 'prog_lib',\n",
    "#        'area_abbr', 'area_lib', 'thema_code', 'destination_code', 'destination_name_en',\n",
    "#        'destination_next_fp', 'programme_name_en', 'programme_code']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_shared import work_csv\n",
    "work_csv(test[['pilier', 'prog_abbr', 'prog_lib', 'programme_code','programme_name_en', 'thema_code','thema_name_en',\n",
    "       'area_abbr', 'area_lib',  'destination_code', 'destination_name_en',\n",
    "       'destination_next_fp', \n",
    "       'programme_next_fp']].drop_duplicates(), 'fp7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.loc[test.thema_code=='ERC',['pilier', 'prog_abbr', 'prog_lib', 'area_abbr', 'area_lib', 'thema_code', 'destination_code']].drop_duplicates()\n",
    "test[[ 'instrument', 'action_code', 'action_name', 'destination_code','action_next_fp']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"- size FP6 after clean thema: {len(x.loc[x.stage=='successful'])}, fund: {'{:,.1f}'.format(x.loc[x.stage=='successful', 'subv_obt'].sum())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns\n",
    "x[['pilier_name_en','programme_name_en', 'programme_code','thema_code','thema_name_en', 'action_code', 'action_name', 'action_next_fp',\n",
    "       'destination_code', 'destination_name_en', 'destination_next_fp', \n",
    "        'pilier_next_fp',\n",
    "       'programme_next_fp']].drop_duplicates().sort_values(['pilier_name_en','programme_code','thema_code'])\n",
    "# x.loc[x.thema_code=='MSCA',['pilier','programme','call_id', 'action', 'action_code2','thema_code',\n",
    "#        'destination_code', 'destination_next_fp']].drop_duplicates().sort_values(['pilier','programme','thema_code'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
